{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"keras_rnn.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"hUlNAh0vxVCc","colab_type":"code","outputId":"06b3b8c5-7087-46ec-c873-73f2043e9533","executionInfo":{"status":"ok","timestamp":1551385343563,"user_tz":240,"elapsed":9066,"user":{"displayName":"Danny Silver","photoUrl":"","userId":"16434078982045343492"}},"colab":{"base_uri":"https://localhost:8080/","height":3641}},"cell_type":"code","source":["\"\"\"\n","keras_rnn.py \n","\n","This is aismple recurrent LSTM netowrk.\n","It learns to remember a sequence of letters, \n","such that it can predict the next one in the series.\n","\n","\"\"\"\n","\n","from __future__ import print_function\n","from __future__ import division\n","\n","import os\n","\n","import numpy as np\n","\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense\n","from keras.optimizers import SGD\n","from keras.utils import to_categorical\n","\n","np.random.seed(1234)  # for consistancy\n","\n","def recurrent():\n","    \"\"\"\n","    Build, train, and evaluate a Recurrent network using Keras\n","    to learn the alphabet\n","    \"\"\"\n","    alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n","    song = [\n","        ['X', 'X', 'A', 'H', 'F', 'E', 'C', 'E', 'B', 'M'],\n","        ['Y', 'Y', 'Y', 'A', 'H', 'F', 'E', 'C', 'E', 'N'],\n","        ['F', 'E', 'F', 'C', 'D', 'E', 'F', 'D', 'B', 'O'],\n","        ['F', 'F', 'F', 'G', 'H', 'G', 'G', 'F', 'E', 'P'],\n","        ['C', 'B', 'A', 'H', 'F', 'E', 'C', 'E', 'B', 'Q'],\n","        ['Z', 'X', 'B', 'A', 'B', 'C', 'D', 'E', 'F', 'R'],\n","        ['W', 'F', 'G', 'H', 'H', 'H', 'G', 'F', 'E', 'L'],\n","        ['W', 'X', 'Y', 'Z', 'D', 'E', 'F', 'G', 'H', 'K']]\n","\n","    data = []\n","    for row in song:\n","        data.append([alphabet.find(el) for el in row])\n","    data = np.array(data)\n","    labels = data[:, -1]\n","    labels = to_categorical(labels, 26)\n","    songs = data[:, :-1]\n","\n","    # reshaping into the form [samples, time steps, features]\n","    songs = np.reshape(songs, [songs.shape[0], songs.shape[1], 1])\n","\n","    model = Sequential()\n","    model.add(LSTM(64, return_sequences=True, input_shape=(songs.shape[1], songs.shape[2])))\n","    model.add(LSTM(32))\n","    model.add(Dense(labels.shape[1], activation='softmax'))\n","\n","    sgd = SGD(lr=0.1, momentum=0.9)\n","\n","    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n","    model.fit(songs, labels, batch_size=4, epochs=100, shuffle=True)\n","    scores = model.evaluate(songs, labels)\n","    print('Accuracy: {0:2.2}'.format(scores[1]))\n","\n","    for _ in range(3):\n","        rand_idx = np.random.randint(0, songs.shape[0])\n","        prediction = model.predict(np.reshape(\n","            songs[rand_idx], [1, 9, 1]))\n","        letter_in = []\n","        for el in songs[rand_idx]:\n","            letter_in.append(alphabet[el[0]])\n","        print(\"{0} -> {1}\".format(letter_in, alphabet[np.argmax(prediction)]))\n","\n","if __name__ == '__main__':\n","    recurrent()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/100\n","8/8 [==============================] - 2s 198ms/step - loss: 3.2465 - acc: 0.0000e+00\n","Epoch 2/100\n","8/8 [==============================] - 0s 4ms/step - loss: 3.0954 - acc: 0.0000e+00\n","Epoch 3/100\n","8/8 [==============================] - 0s 3ms/step - loss: 2.8807 - acc: 0.1250\n","Epoch 4/100\n","8/8 [==============================] - 0s 4ms/step - loss: 2.6723 - acc: 0.1250\n","Epoch 5/100\n","8/8 [==============================] - 0s 4ms/step - loss: 2.5024 - acc: 0.0000e+00\n","Epoch 6/100\n","8/8 [==============================] - 0s 4ms/step - loss: 2.3288 - acc: 0.1250\n","Epoch 7/100\n","8/8 [==============================] - 0s 4ms/step - loss: 2.2267 - acc: 0.2500\n","Epoch 8/100\n","8/8 [==============================] - 0s 4ms/step - loss: 2.2061 - acc: 0.1250\n","Epoch 9/100\n","8/8 [==============================] - 0s 4ms/step - loss: 2.1871 - acc: 0.1250\n","Epoch 10/100\n","8/8 [==============================] - 0s 4ms/step - loss: 2.1482 - acc: 0.1250\n","Epoch 11/100\n","8/8 [==============================] - 0s 4ms/step - loss: 2.1487 - acc: 0.1250\n","Epoch 12/100\n","8/8 [==============================] - 0s 4ms/step - loss: 2.1479 - acc: 0.1250\n","Epoch 13/100\n","8/8 [==============================] - 0s 4ms/step - loss: 2.1471 - acc: 0.0000e+00\n","Epoch 14/100\n","8/8 [==============================] - 0s 4ms/step - loss: 2.0511 - acc: 0.3750\n","Epoch 15/100\n","8/8 [==============================] - 0s 4ms/step - loss: 1.9945 - acc: 0.2500\n","Epoch 16/100\n","8/8 [==============================] - 0s 3ms/step - loss: 1.8444 - acc: 0.3750\n","Epoch 17/100\n","8/8 [==============================] - 0s 4ms/step - loss: 1.7470 - acc: 0.3750\n","Epoch 18/100\n","8/8 [==============================] - 0s 4ms/step - loss: 1.6463 - acc: 0.2500\n","Epoch 19/100\n","8/8 [==============================] - 0s 4ms/step - loss: 1.9755 - acc: 0.1250\n","Epoch 20/100\n","8/8 [==============================] - 0s 4ms/step - loss: 1.6413 - acc: 0.2500\n","Epoch 21/100\n","8/8 [==============================] - 0s 4ms/step - loss: 1.6538 - acc: 0.2500\n","Epoch 22/100\n","8/8 [==============================] - 0s 4ms/step - loss: 2.3572 - acc: 0.0000e+00\n","Epoch 23/100\n","8/8 [==============================] - 0s 4ms/step - loss: 1.8828 - acc: 0.2500\n","Epoch 24/100\n","8/8 [==============================] - 0s 4ms/step - loss: 2.3184 - acc: 0.1250\n","Epoch 25/100\n","8/8 [==============================] - 0s 4ms/step - loss: 2.3145 - acc: 0.1250\n","Epoch 26/100\n","8/8 [==============================] - 0s 4ms/step - loss: 2.0743 - acc: 0.1250\n","Epoch 27/100\n","8/8 [==============================] - 0s 4ms/step - loss: 2.0188 - acc: 0.1250\n","Epoch 28/100\n","8/8 [==============================] - 0s 4ms/step - loss: 1.6764 - acc: 0.3750\n","Epoch 29/100\n","8/8 [==============================] - 0s 4ms/step - loss: 1.5409 - acc: 0.6250\n","Epoch 30/100\n","8/8 [==============================] - 0s 4ms/step - loss: 1.4907 - acc: 0.3750\n","Epoch 31/100\n","8/8 [==============================] - 0s 4ms/step - loss: 1.5987 - acc: 0.1250\n","Epoch 32/100\n","8/8 [==============================] - 0s 4ms/step - loss: 1.2569 - acc: 0.6250\n","Epoch 33/100\n","8/8 [==============================] - 0s 4ms/step - loss: 1.4361 - acc: 0.2500\n","Epoch 34/100\n","8/8 [==============================] - 0s 4ms/step - loss: 1.3150 - acc: 0.3750\n","Epoch 35/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.9305 - acc: 0.6250\n","Epoch 36/100\n","8/8 [==============================] - 0s 4ms/step - loss: 1.1539 - acc: 0.3750\n","Epoch 37/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.8400 - acc: 0.7500\n","Epoch 38/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.9906 - acc: 0.5000\n","Epoch 39/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.9947 - acc: 0.5000\n","Epoch 40/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.5794 - acc: 0.7500\n","Epoch 41/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.9724 - acc: 0.5000\n","Epoch 42/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.7237 - acc: 0.7500\n","Epoch 43/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.7362 - acc: 0.7500\n","Epoch 44/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.7434 - acc: 0.6250\n","Epoch 45/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.5605 - acc: 0.8750\n","Epoch 46/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.9153 - acc: 0.6250\n","Epoch 47/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.7388 - acc: 0.6250\n","Epoch 48/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.9257 - acc: 0.6250\n","Epoch 49/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.4491 - acc: 0.7500\n","Epoch 50/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.4862 - acc: 0.6250\n","Epoch 51/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.3826 - acc: 0.8750\n","Epoch 52/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.3443 - acc: 0.7500\n","Epoch 53/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.2526 - acc: 1.0000\n","Epoch 54/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.2518 - acc: 1.0000\n","Epoch 55/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.2113 - acc: 1.0000\n","Epoch 56/100\n","8/8 [==============================] - 0s 3ms/step - loss: 0.2141 - acc: 0.8750\n","Epoch 57/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1900 - acc: 0.8750\n","Epoch 58/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1600 - acc: 1.0000\n","Epoch 59/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1357 - acc: 1.0000\n","Epoch 60/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.1058 - acc: 1.0000\n","Epoch 61/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0910 - acc: 1.0000\n","Epoch 62/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0821 - acc: 1.0000\n","Epoch 63/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0773 - acc: 1.0000\n","Epoch 64/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0810 - acc: 1.0000\n","Epoch 65/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0588 - acc: 1.0000\n","Epoch 66/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0518 - acc: 1.0000\n","Epoch 67/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0562 - acc: 1.0000\n","Epoch 68/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0447 - acc: 1.0000\n","Epoch 69/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0413 - acc: 1.0000\n","Epoch 70/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0410 - acc: 1.0000\n","Epoch 71/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0348 - acc: 1.0000\n","Epoch 72/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0310 - acc: 1.0000\n","Epoch 73/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0291 - acc: 1.0000\n","Epoch 74/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0276 - acc: 1.0000\n","Epoch 75/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0261 - acc: 1.0000\n","Epoch 76/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0238 - acc: 1.0000\n","Epoch 77/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0229 - acc: 1.0000\n","Epoch 78/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0219 - acc: 1.0000\n","Epoch 79/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0198 - acc: 1.0000\n","Epoch 80/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0190 - acc: 1.0000\n","Epoch 81/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0185 - acc: 1.0000\n","Epoch 82/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0177 - acc: 1.0000\n","Epoch 83/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0166 - acc: 1.0000\n","Epoch 84/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0159 - acc: 1.0000\n","Epoch 85/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0153 - acc: 1.0000\n","Epoch 86/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0148 - acc: 1.0000\n","Epoch 87/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0143 - acc: 1.0000\n","Epoch 88/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0140 - acc: 1.0000\n","Epoch 89/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0135 - acc: 1.0000\n","Epoch 90/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0131 - acc: 1.0000\n","Epoch 91/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0126 - acc: 1.0000\n","Epoch 92/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0123 - acc: 1.0000\n","Epoch 93/100\n","8/8 [==============================] - 0s 5ms/step - loss: 0.0119 - acc: 1.0000\n","Epoch 94/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0117 - acc: 1.0000\n","Epoch 95/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0115 - acc: 1.0000\n","Epoch 96/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0112 - acc: 1.0000\n","Epoch 97/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0109 - acc: 1.0000\n","Epoch 98/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0107 - acc: 1.0000\n","Epoch 99/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0105 - acc: 1.0000\n","Epoch 100/100\n","8/8 [==============================] - 0s 4ms/step - loss: 0.0103 - acc: 1.0000\n","8/8 [==============================] - 0s 21ms/step\n","Accuracy: 1.0\n","['F', 'F', 'F', 'G', 'H', 'G', 'G', 'F', 'E'] -> P\n","['F', 'E', 'F', 'C', 'D', 'E', 'F', 'D', 'B'] -> O\n","['W', 'F', 'G', 'H', 'H', 'H', 'G', 'F', 'E'] -> L\n"],"name":"stdout"}]}]}