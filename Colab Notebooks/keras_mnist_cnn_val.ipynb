{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"keras_mnist_cnn_val.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"DAb3GiM70C2w","colab_type":"code","outputId":"f30be06c-779b-4fb8-ca17-be440194fcf5","executionInfo":{"status":"error","timestamp":1551386254239,"user_tz":240,"elapsed":9224,"user":{"displayName":"Danny Silver","photoUrl":"","userId":"16434078982045343492"}},"colab":{"base_uri":"https://localhost:8080/","height":1204}},"cell_type":"code","source":["\"\"\"\n","keras_mnist_cnn_val.py\n","\n","Demonstrating convolution neural networks\n","using Keras with a TensorFlow backend. Keras\n","is a high level machine learning package\n","which supports convolution, recurrent, and\n","standard neural networks, as well as allowing\n","you to define your own layer.\n","\"\"\"\n","import numpy as np\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n","from keras.optimizers import SGD\n","from keras.callbacks import EarlyStopping\n","from tensorflow.examples.tutorials.mnist import input_data\n","\n","import matplotlib.pyplot as plt\n","\n","batch_size = 128\n","num_classes = 10\n","epochs = 10\n","\n","train_ex = 1000\n","img_h, img_w = 28, 28\n","\n","def get_data():\n","    \"\"\"\n","    Loads the data in, choose the number of training\n","    examples we want, and reshape the x data to the\n","    correct shape (28x28x1).\n","    \"\"\"\n","    mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n","\n","    if train_ex is not None:\n","        assert mnist.train.images.shape[0] >= train_ex, \\\n","            'Cannot train with more examples than you have'\n","        x_train = mnist.train.images[:train_ex]\n","        y_train = mnist.train.labels[:train_ex]\n","\n","    x_tune = mnist.validation.images\n","    x_test = mnist.test.images\n","\n","    x_train = x_train.reshape(x_train.shape[0], img_h, img_w, 1)\n","    x_tune = x_tune.reshape(x_tune.shape[0], img_h, img_w, 1)\n","    x_test = x_test.reshape(x_test.shape[0], img_h, img_w, 1)\n","\n","    y_tune = mnist.validation.labels\n","    y_test = mnist.test.labels\n","\n","    return x_train, y_train, x_tune, y_tune, x_test, y_test\n","\n","\n","def convolution():\n","    \"\"\"\n","    Keras follows the layers principle, where each layer\n","    is independent and can be stacked and merged together.\n","    The Sequential model assumes that there is one long\n","    stack, with no branching.\n","    \"\"\"\n","    x_train, y_train, x_tune, y_tune, x_test, y_test = get_data()\n","\n","    model = Sequential()\n","\n","    \"\"\"\n","    filters gives us the number of filters in the layer,the\n","    more filters we have, the more information we can learn\n","\n","    kernel_size is the size of the convolution filter\n","\n","    activation is the activation function on each node,\n","    we use relu, could also use sigmoid\n","\n","    input_shape is the shape of the image. We reshaped\n","    the data above to get it in the right shape. The 1\n","    represents a grayscale image. If you had a colour\n","    image (RGB), the last dimension would be 3.\n","    \"\"\"\n","    model.add(Conv2D(filters=32, kernel_size=(3, 3),\n","                     activation='relu',\n","                     input_shape=(img_h, img_w, 1)))\n","\n","    \"\"\"\n","    MaxPooling takes an NxM rectangle and find the maxiumum\n","    value in that square, and discards the rest. Since we are\n","    doing 2x2 pooling, it has the effect of halving the height\n","    and width of the image.\n","    \"\"\"\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    # Sets a random 25% of nodes to 0 to prevent overfitting\n","    model.add(Dropout(0.25))\n","\n","    # Note we don't need to give the shape between the first and\n","    # second layer, Keras figures that out for us.\n","    model.add(Conv2D(32, kernel_size=(2, 2),\n","        activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    # Before we had 6x6x32, now we have a flat 1152\n","    model.add(Flatten())\n","\n","    # your standard fully connected NN layer\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(num_classes, activation='softmax'))\n","\n","    # Stochastic Gradient Descent\n","    sgd = SGD(lr=0.01, momentum=0.9)\n","    es = EarlyStopping(monitor='val_loss',\n","                       patience=5,  # epochs to wait after min loss\n","                       min_delta=0.0001)  # anything less than this counts as no change\n","\n","    model.compile(loss=keras.losses.categorical_crossentropy,\n","                  optimizer=sgd,\n","                  metrics=['accuracy'])\n","\n","    model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              verbose=1,\n","              validation_data=(x_tune, y_tune),\n","              callbacks=[es])\n","\n","    score = model.evaluate(x_test, y_test)\n","    print('Test loss: {0}'.format(score[0]))\n","    print('Test accuracy: {0}'.format(score[1]))\n","\n","\n","    plt.figure('Predictions on MNIST', facecolor='gray')\n","    plt.set_cmap('gray')\n","\n","    predictions = model.predict(x_test, verbose=0)\n","\n","    for i in range(5):\n","        subplt = plt.subplot(int(i / 5) + 1, 5, i + 1)\n","        # no sense in showing labels if they don't match the letter\n","        hot_index = np.argmax(predictions[i])\n","        subplt.set_title('Prediction: {0}'.format(hot_index))\n","        subplt.axis('off')\n","        letter = x_test[i]\n","        subplt.matshow(np.reshape(letter, [img_h, img_w]))\n","        plt.draw()\n","\n","if __name__ == '__main__':\n","    convolution()\n","    plt.show()\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","Train on 1000 samples, validate on 5000 samples\n","Epoch 1/10\n","1000/1000 [==============================] - 2s 2ms/step - loss: 2.2926 - acc: 0.1330 - val_loss: 2.2774 - val_acc: 0.1710\n","Epoch 2/10\n","1000/1000 [==============================] - 2s 2ms/step - loss: 2.2532 - acc: 0.1770 - val_loss: 2.2260 - val_acc: 0.2202\n","Epoch 3/10\n","1000/1000 [==============================] - 2s 2ms/step - loss: 2.1759 - acc: 0.2350 - val_loss: 2.1302 - val_acc: 0.2624\n","Epoch 4/10\n","1000/1000 [==============================] - 2s 2ms/step - loss: 2.0346 - acc: 0.3190 - val_loss: 1.9107 - val_acc: 0.4866\n","Epoch 5/10\n"," 640/1000 [==================>...........] - ETA: 0s - loss: 1.8330 - acc: 0.4094"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-ebf0704e8949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mconvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-ebf0704e8949>\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m               callbacks=[es])\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}